\chapter{Conclusions and Future Work} \label{chap_5}

In this last chapter, we will summarize the work presented in this thesis. After that, we will present some directions for future work that could be explored to further improve our solution and the impact it can have in malware analysis research.

\section{Conclusion}
This work first introduced the concepts of fuzzing and sanitizers, a popular bug-detection approach in testing environments that has proven to be particularly effective, especially when combined with the "Continuous-Fuzzing/Continuous-Integration" pipeline that many modern organizations employ when developing their products. Then, we introduced autonomous fuzzing frameworks, how they work and described the chosen frameworks analyzed. Followed a description of the methodology used to analyze said frameworks along with how bugs were collected, analyzed and reported. Concludes a thorough analysis of the results, discussing how developers perceived the bug reports created and the implications of the behaviors observed with some case studies.

This study highlighted the popularity of autonomous fuzzing infrastructures and their effectiveness, but also that the lack of standardized approaches and design trade-offs are major contributors to their accuracy when it comes to automatically detecting and reporting bugs. Although the overall number of projects analyzed is not representative for the entire campaigns, the applied methodology still managed to discover several hundreds of previously unreported bugs, showing that the workflow adopted by the analyzed campaign present flaws that lead to overlooked bugs and potential vulnerabilities.

In today's world, where software development techniques are constantly changing and improving, it is crucial to ensure that all aspects of software development progress at the same pace, including the "Testing" phase: many organization rely on automated testing, a time-efficient and effective solution, but that comes with its own shortcomings as highlighted by this work. Therefore, while relying on autonomous testing techniques and infrastructures has proven its efficacy in time, developers should monitor, configure and employ these tools regularly and maintain them up to date to ensure that also the testing environments can be as accurate and productive as possible.


\newpage
\section{Future Work}

\matteo{Expand this work to other fuzzing frameworks? We found some issues that are general (e.g. use as many sanitizers as possible), but also issues that are specific to the frameworks we tested: other frameworks might have different issues specific to them}

\matteo{Provide general guidelines for fuzzing frameworks. Right now there is none, users just adhere to common sense; we could study and propose guidelines that prevent the issues we witnessed.}

\matteo{can we think of something else? maybe something related to sanitizers}